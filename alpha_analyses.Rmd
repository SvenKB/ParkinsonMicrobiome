---
title: "Alpha diversity analyses"
author: "Sven Kleine Bardenhorst"
date: "`r format(Sys.time(), '%d %B %Y')`"
mail: "s.kleinebardenhorst@uni-muenster.de"
twitter: "r_graph_gallery"
github: "svenkb"
home: "epi.uni-muenster.de"
# !!! You need to provide a logo image here !!! Or just delete the field for no logo
logo: "Logo_WWU.svg"
output:
  epuRate::epurate:
    toc: TRUE
    number_sections: FALSE
    code_folding: "hide"
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo=TRUE, message=FALSE, warning=FALSE,fig.width = 12)
```

```{css include=FALSE}
body .main-container {
max-width: 1600px;
}
```

```{css zoom-lib-src, echo = FALSE}
script src = "https://ajax.googleapis.com/ajax/libs/jquery/3.4.1/jquery.min.js"
```

```{js zoom-jquery, echo = FALSE}
 $(document).ready(function() {
    $('body').prepend('<div class=\"zoomDiv\"><img src=\"\" class=\"zoomImg\"></div>');
    // onClick function for all plots (img's)
    $('img:not(.zoomImg)').click(function() {
      $('.zoomImg').attr('src', $(this).attr('src')).css({width: '100%'});
      $('.zoomDiv').css({opacity: '1', width: 'auto', border: '1px solid white', borderRadius: '5px', position: 'fixed', top: '50%', left: '50%', marginRight: '-50%', transform: 'translate(-50%, -50%)', boxShadow: '0px 0px 50px #888888', zIndex: '50', overflow: 'auto', maxHeight: '100%'});
    });
    // onClick function for zoomImg
    $('img.zoomImg').click(function() {
      $('.zoomDiv').css({opacity: '0', width: '0%'}); 
    });
  });
```

```{r load packages, message=FALSE, warning=FALSE, include=FALSE}
#### load packages ####
source('packages.R')

#### load functions ####
source("functions.R")
```


# Prepare alpha diversity measures
```{r echo=TRUE, message=FALSE, warning=FALSE}
dat <- readRDS("phyl_list.RDS")

alpha_dat <- estimate_alpha(dat)

author.names <- c("Pietrucci et al., 2019",
           "Qian et al., 2018",
           "Keshavarzian et al., 2015",
           "Aho et al., 2019",
           "Heintz-Buschart et al., 2018",
           "Weis et al., 2019",
           "Barichella et al., 2019")

```


```{r echo=TRUE, fig.height=7, fig.width=10, message=FALSE, warning=FALSE}

ggplot(aes(x=as.factor(author),y=(richness)),data=alpha_dat) +
  geom_boxplot(aes(fill=status)) +
  scale_fill_brewer(palette = "Set1") +
  theme(axis.text.x = element_text(angle = 90))

ggplot(aes(x=as.factor(author),y=(shannon)),data=alpha_dat) +
  geom_boxplot(aes(fill=status)) +
  scale_fill_brewer(palette = "Set1") +
  theme(axis.text.x = element_text(angle = 90))

ggplot(aes(x=as.factor(author),y=inv.simpson),data=alpha_dat) +
  geom_boxplot(aes(fill=status)) +
   scale_fill_brewer(palette = "Set1") +
  theme(axis.text.x = element_text(angle = 90))
```

## Estimate alpha diversity by effective number of taxa through hill numbers

The problems with indices like Simpson or Shannon is that they are not diversities by themselves, but only proxies (indices) of the true underlying diversity. However, often every index is treated like a true diversity, which may lead to misleading results for several reasons. At first, indices define diversity in different ways, e.g. some focus solely on the number of present taxa (further referred to as richness), while others incorporate the relative abundance of all present taxa (further referred to as eveness). The combination of speciess richness and eveness into one index makes it hard to interpret. It further leads to the second problem, that some indices do NOT double when the true diversity doubles, hence, they are highly non-linear. As an example, a community with a Shannon-Index ($H'$) of 2 is not twice as diverse as a community with a $H'$ of 1. In addition, on the $H'$-scale, the difference between 1 and 2 is not equal to the difference between 3 and 4. Thus, the location of a mean difference on the $H'$-scale matters. This makes the statisical analysis and interpretation of alpha diversity indices problematic. However, there is a straightforward and intuitive way to define a true diversity in terms of **effective number of species** through hill numbers.

```{r}
x <- rep(150,50)
shannon <- function(x) {-sum( (x/sum(x)) * log(x/sum(x)) )}
s_x <- shannon(x)
```

Given a specific value of $H'$, we cannot derive the true diversity of the community, as we cannot decompose the value into its richness and eveness parts. However, we still know that two communities with an equal index are always equally diverse. 

Suppose we have two communities with `r length(x)` equally abundant taxa. We can calculate the Shannon-Index for this community with

$$
H' = - \sum_i p_i * ln  p_i
$$


with $p_i = \frac{n_i}{N}$. For the given example, $H'$ is `r s_x`. Now, we know the $H'$ of a community with `r length(x)` equally abundant taxa. Therefore, we can conclude that every community with an $H'$ of `r s_x` is always as diverse as a community with `r length(x)` equally abundant taxa.

We can make use of this fact, by transforming the $H'$ into the **effective number of species**, which is simply done by exponantation of $H'$.

$$
\exp(H') = exp(3.912023) = 50
$$
The same logic can be applied to other measures of diversity. In fact, the effective number of species based on the most commonly used diversity indices can be calculated directly by the generalized formula

$$
qD = (\sum_{i_=1}^Sp_i^q)^{1/(1-q)},
$$
which is the Hill number of order q. The expression if fully dependent on the choice of q, the exponent of taxa abundances, thus, determining the weight that is assigned to the evenness of taxa. The higher the value of q, the higher the influence of eveness on the value of the index.

Different values of q correspond to the most frequently used diversity measures. Here, we will focus on $q=0$ (species richness), $q=1$ (exponential of the Shannon index; note that it is not exactly 1, as the formula is not defined for $q=1$, but its limit when q tends to 1) and $q=2$ (the inverse of Simpson's concentration index).

### Alpha diveristy analysis through hill numbers

A common problem with all diversity indices is their dependency on the sampling depth (library size). We can inspect this dependency by correlating the value of the hill numbers of different order with the respective library size.

```{r echo=TRUE, message=FALSE, warning=FALSE, results='asis'}
## Asses whether alpha-diversity associated with sequencing depth
alpha_dat %>% group_by(author) %>% summarize(Richness = round(cor(richness,N),2),
                                             Shannon = round(cor(shannon,N),2),
                                             "Inverse simpson" = round(cor(inv.simpson,N),2)) %>% column_to_rownames("author") %>% t %>% kable(caption = "Correlation of alpha diversity indices with library size") %>% kableExtra::kable_styling("striped")
```

In our setting, this challenge is even more complex, as the library size is not only different between individuals, but also cluster within studies and sometimes within study groups nested in these studies.

```{r echo=TRUE, fig.height=7, fig.width=10, message=FALSE, warning=FALSE, fig.cap="Average library size per study and per study group."}
#alpha_dat %>% group_by(author,status) %>% summarize(avg_LS = mean(N)) %>%
#  ggplot(aes(x=author,y=avg_LS,fill=status)) +
#  geom_bar(stat="identity",position = "dodge") +
#   scale_fill_brewer(palette="Set1") +
#  scale_x_discrete(labels=addline_format(unique(alpha_dat$author))) +
#  theme_sjplot()

alpha_dat %>%
  ggplot(aes(x=author,y=N,fill=status)) +
  geom_boxplot() +
   scale_fill_brewer(palette="Set1") +
  scale_x_discrete(labels=addline_format(unique(alpha_dat$author))) +
  theme_sjplot() +
  ylab("Library size") +
  xlab("Study") +
  labs(fill="Disease status")
  
```

```{r echo=TRUE, fig.height=7, fig.width=10, message=FALSE, warning=FALSE, fig.cap="Distribution of library size per study and per study group."}
alpha_dat %>% dplyr::select(status,N,study) %>%
  ggplot(aes(x=N,fill=status)) +
  geom_density(alpha=.6) +
  scale_fill_brewer(palette="Set1") +
  facet_wrap(~alpha_dat$author,ncol = 3,scales = "free_x") +
  theme_sjplot() +
  xlab("Library size") +
  labs(fill="Disease status")
```

A common approach to handle unequal library sizes is by rarefaction, thus, sub-sampling from each sample to achieve equal library sizes that allow for fair comparisons However, this approach is highly criticized for several reasons, among which is the discarding of valuable data. Therefore, we will use a poisson model including the library size as an offset, conditioning the estimates on the library size. Using this approach, we will incorporate the uncertainty associated with the library size (cases will be weighted according to their library size), without throwing away any information.

# Random Effects models for alpha diversity

## Two-stage approach

```{r fig.cap="Two stage meta-analysis using poisson regression with library size as offset - richness."}
alpha_dat2 <- alpha_dat %>% dplyr::select(ID,status,everything()) %>% filter(N>10)

## metafor two-stage approach
library(metafor)

met_dat <- alpha_dat2 %>%
  dplyr::select(study,status,richness,N,author) %>%
  group_by(study,status) %>%
  summarise(richness = sum(richness),
            N = sum(N),
            author = first(author)) %>%
  pivot_wider(names_from=status,values_from=c(richness,N))

res <- rma(measure = "IRR",x2i=richness_HC,x1i=richness_PD,t2i=N_HC,t1i=N_PD,data=met_dat)

forest(res,transf = exp,refline = 1,slab = unique(alpha_dat2$author))
```

```{r fig.cap="Two stage meta-analysis using poisson regression with library size as offset - shannon."}
## metafor two-stage approach

met_dat <- alpha_dat2 %>%
  dplyr::select(study,status,shannon,N,author) %>%
  group_by(study,status) %>%
  summarise(shannon = sum(shannon),
            N = sum(N),
            author = first(author)) %>%
  pivot_wider(names_from=status,values_from=c(shannon,N))

res <- rma(measure = "IRR",x2i=shannon_HC,x1i=shannon_PD,t2i=N_HC,t1i=N_PD,data=met_dat)

forest(res,transf = exp,refline = 1,slab = unique(alpha_dat2$author))
```

```{r fig.cap="Two stage meta-analysis using poisson regression with library size as offset - inv.simpson"}
## metafor two-stage approach
met_dat <- alpha_dat2 %>%
  dplyr::select(study,status,inv.simpson,N,author) %>%
  group_by(study,status) %>%
  summarise(inv.simpson = sum(inv.simpson),
            N = sum(N),
            author = first(author)) %>%
  pivot_wider(names_from=status,values_from=c(inv.simpson,N))

res <- rma(measure = "IRR",x2i=inv.simpson_HC,x1i=inv.simpson_PD,t2i=N_HC,t1i=N_PD,data=met_dat)

forest(res,transf = exp,refline = 1,slab = unique(alpha_dat2$author))
```
## One-stage approach

### Bayesian multilevel models

```{r echo=FALSE, message=FALSE, warning=FALSE}
library(brms)
library(tidybayes)
library(ggridges)
library(glue)


#fit <- brms::brm(richness~1+status+offset(log(N))+(1|study),
#                 data=alpha_dat,
#                 family =gaussian(),
#                 iter=500)

#fit1 <- brms::brm(richness~1+status+(1|study),
#                 data=alpha_dat,
#                 family =gaussian(),
#                 iter=500)

#fit2 <- brms::brm(shannon~1+status+offset(log(N))+(1|study),
#                 data=alpha_dat,
#                 family = poisson(),
#                 iter=500)

#fit3 <- brms::brm(shannon~1+status+offset(log(N))+(1+status|study),
#                 data=alpha_dat,
#                 family = poisson(),
#                 iter=1000)
#saveRDS(fit3,"poisson_fit_shannon.RDS")
fit3 <- readRDS("poisson_fit_shannon.RDS")
#fit4 <- brms::brm(shannon~1+status+(1+status|study),
#                 data=alpha_dat,
#                 family = gaussian(),
#                 iter=1000)
#saveRDS(fit4,"gaussian_fit_shannon.RDS")
fit4 <- readRDS("gaussian_fit_shannon.RDS")


```

```{r}
pp_check(fit3,nsamples = 50)
pp_check(fit4,nsamples = 50)

```

```{r}
# Study effects
#posterior <- posterior_samples(fit4)

study.draws <- fit3 %>% spread_draws(b_Intercept,
                                     b_statusPD,
                                     r_study[study,effect]) %>%
  filter(effect=="statusPD") %>%
  mutate(b_statusPD = r_study + b_statusPD) %>%
  mutate(b_statusPD = exp(b_statusPD)) %>%
  dplyr::select(.chain,.iteration,.draw,b_statusPD,study) %>% convert(fct(study)) %>%
  mutate(study = case_when(study==1 ~ author.names[[1]],
                           study==2 ~ author.names[[2]],
                           study==3 ~ author.names[[3]],
                           study==4 ~ author.names[[4]],
                           study==5 ~ author.names[[5]],
                           study==6 ~ author.names[[6]],
                           study==7 ~ author.names[[7]]))

# Pooled effect
pooled.draws <- spread_draws(fit3,b_statusPD) %>%
  mutate(b_statusPD = exp(b_statusPD),
         study = "Pooled Effect")


forest.data <- bind_rows(study.draws, pooled.draws) %>% 
   ungroup() %>%
   mutate(study = reorder(study,b_statusPD))

forest.data.summary <- group_by(forest.data, study) %>% 
  mean_qi(b_statusPD)


gg_color_hue <- function(n) {
  hues = seq(15, 375, length = n + 1)
  hcl(h = hues, l = 65, c = 100)[1:n]
}

cols = gg_color_hue(length(levels(forest.data$study)))


ggplot(aes(b_statusPD, relevel(study, "Pooled Effect", after = Inf)), 
       data = forest.data) +
  geom_vline(xintercept = exp(fixef(fit3)[2, 1]), color = "grey", size = 1) +
  geom_vline(xintercept = exp(fixef(fit3)[2, 3:4]), color = "grey", linetype = 2) +
  geom_vline(xintercept = 1, color = "black", size = 1) +
  geom_density_ridges(fill = "blue", rel_min_height = 0.01, col = NA, scale = 1,
                      alpha = 0.6) +
  geom_pointintervalh(data = forest.data.summary, size = 1) +
  geom_text(data = mutate_if(forest.data.summary, is.numeric, round, 2),
    aes(label = glue("{b_statusPD} [{.lower}, {.upper}]"), x = Inf), hjust = "inward") +
  labs(x = "Incidence Rate Ratio",
       y = element_blank()) +
  theme_minimal()
```

```{r}
## One-stage approach

## Asses ICC
ICC(outcome = "richness",group="study",data=alpha_dat)
fit <- lme4::glmer(richness~1+(status|study),data=alpha_dat2,family=poisson(link="log"),offset = log(N))
fit2 <- lme4::glmer(shannon~1+(status|study),data=alpha_dat2,family=poisson(link="log"),offset = log(N))
fit3 <- lme4::glmer(inv.simpson~1+(status|study),data=alpha_dat2,family=poisson(link="log"),offset = log(N))
names <- alpha_dat %>% group_by(study) %>% slice(1) %>% dplyr::select(author)

exp(ranef(fit)$study) %>% t() %>% kable(caption = "Random effects poisson regression with library size as offset - richness") %>% kableExtra::kable_styling()
exp(ranef(fit2)$study) %>% t() %>% kable(caption = "Random effects poisson regression with library size as offset - shannon") %>% kableExtra::kable_styling()
exp(ranef(fit3)$study) %>% t() %>% kable(caption = "Random effects poisson regression with library size as offset - inv.simpson") %>% kableExtra::kable_styling()
```

## Sensitivity to library size

```{r}
range <- alpha_dat %>% filter(study == 2 & N > 0) %>% dplyr::select(N) %>% range
```


There are some studies in which the library size is highly variable, e.g. the study by *Qian et al. (2018)* ranges from `r range[1] ` to `r range[2]` reads per sample. As samples with low reads may be very unreliable/uninformative, we may decide on a cut-off value for a minimum library size. To make a more informed choice, we may conduct a sensitivity analysis to get a feeling for the influence of the library size on the results.
For this sensitivity analysis, we will perform the analysis repeatedly for different minimum library sizes and plot the coefficients as a function of library size.


```{r fig.cap="Sensitivity", fig.height=5, fig.width=10}
sensitivity_ls(alpha_dat, index = "richness")
```

```{r fig.cap="Sensitivity", fig.height=5, fig.width=10}
sensitivity_ls(alpha_dat, index = "shannon")
```

```{r fig.cap="Sensitivity", fig.height=5, fig.width=10}
sensitivity_ls(alpha_dat, index = "inv.simpson")
```



# Extrapolation of alpha diversity

```{r eval=FALSE, include=FALSE}
A_next <- iNEXT::iNEXT(data.frame(t(A_dat[,-1])),q=0)
p <- ggiNEXT(A_next,type = 1) +
  theme(legend.position = "none")

A_next$iNextEst$X1

p.dat <- fortify(A_next,type=2)

p.dat$method <- factor(p.dat$method, c("interpolated", "extrapolated"),c("interpolation", "extrapolation"))

ggplot(aes(x=x,y=y,fill=site,col=site),data=p.dat) +
  geom_line(aes(linetype=method),size=1,alpha=.4) +
  theme(legend.position = "none") +
  scale_x_continuous(labels=comma)

```


```{r eval=FALSE, include=FALSE}
d <- lapply(dat,function(x) aggregate_taxa(x,"Sequence"))

datA <- data.frame(otu_table(d[[1]]))
str(datA)


iAd <- iNEXT::iNEXT(datA,q=0,datatype="abundance")


Ad <- iNEXT::estimateD(datA,datatype = "abundance",base="size",level=100000,conf=0.95)


```

